---
title: "Project Title"
author: "Your Name"
date: "`r Sys.Date()`"
output: html_document
---

# Problem Definition

简要描述你要解决的问题，包括背景、目标和预期成果。

---


```{r}
 #Load dataset
df <- read.csv("listings.csv")
```

# Data Description
The dataset is obtained from [Inside Airbnb](http://insideairbnb.com/), which provides detailed information about Airbnb listings across different cities. The dataset includes listing-level features such as location, property attributes, host information, and price. 
In this project, we focus on the Sydney dataset.  
  
The dataset contains **`r nrow(df)` rows** and **`r ncol(df)` columns**. Variables can be grouped into three categories:  
  - **Numerical variables:** price, minimum_nights, number_of_reviews, reviews_per_month, etc.  
  - **Categorical variables:** room_type, neighbourhood, host_is_superhost, etc.  
  - **Text variables:** listing name, description, host name, etc

# Data Challenges
During initial exploration, the following challenges are identified:
Missing values: Some variables (e.g., reviews_per_month) contain many missing entries.
Outliers: Price contains extreme values that may distort the distribution.
Class imbalance: Some categories (e.g., specific neighbourhoods or room types) dominate the dataset.
Text variables: Variables like description and name require NLP techniques if used

| Variable Type / 变量类型 | Examples / 示例                                  | Notes / 备注                                         |
| -------------------- | ---------------------------------------------- | -------------------------------------------------- |
| Numerical 数值型        | price, minimum\_nights, number\_of\_reviews    | Require cleaning and outlier handling / 需要清洗和异常值处理 |
| Categorical 类别型      | room\_type, neighbourhood, host\_is\_superhost | Require encoding / 需要编码                            |
| Text 文本型             | name, description, host\_name                  | Optional features, may need NLP / 可选特征，可能需要 NLP    |
| Outcome 目标变量         | price\_category (Low/Medium/High)              | Derived from price / 由价格变量派生                       |


# Logical Connection

These observations highlight both the richness and the challenges of the dataset. This naturally leads to the next step: Data Cleaning & Feature Engineering, where missing values, outliers, and categorical variables will be addressed to prepare the dataset for modeling.

```{r}
# Dataset preview 
#str(df)
#head(df)


```
---

# Data Cleaning & Feature Engineering
1. Price Column Processing & Outlier Detection
This R code finds the price column, cleans its data by removing non-numeric characters, converts it to a numeric type, and removes any rows where the price is 0 or less. It then performs an outlier analysis based on the IQR method.
```{r}
library(tidyverse)

# Re-read the cleaned data from the previous step
df <- read_csv("listings.csv", col_types = cols(.default = "c"))

# Step 1: Find the price column
price_col <- NULL
possible_cols <- names(df)

# Check for 'price' (case-insensitive)
price_col <- possible_cols[str_detect(tolower(possible_cols), "price")][1]
if (is.na(price_col)) {
  # If not found, check for other keywords
  price_keywords <- c('cost', 'amount', 'value', 'fee', 'charge', 'payment')
  for (keyword in price_keywords) {
    found_col <- possible_cols[str_detect(tolower(possible_cols), keyword)][1]
    if (!is.na(found_col)) {
      price_col <- found_col
      break
    }
  }
}

if (is.na(price_col)) {
  stop("Error: Could not find a column representing price.")
}

message(paste0("Using '", price_col, "' as the price column."))

# Step 2: Clean and convert the price column (corrected)
df <- df %>%
  mutate(
    # Remove commas and non-numeric characters, then convert to numeric.
    # `as.numeric` will correctly convert invalid values to `NA`.
    !!sym(price_col) := as.numeric(str_remove_all(str_remove_all(tolower(!!sym(price_col)), ","), "[^\\d.-]"))
  ) %>%
  # Now, filter out rows where the price is NA or <= 0
  filter(!is.na(!!sym(price_col)) & !!sym(price_col) > 0)

message(paste0("Effective price data rows: ", nrow(df)))

# Step 3: Analyze outliers using IQR (will now work correctly)
q1 <- quantile(df[[price_col]], 0.25)
q3 <- quantile(df[[price_col]], 0.75)
iqr <- q3 - q1
lower_bound <- q1 - 1.5 * iqr
upper_bound <- q3 + 1.5 * iqr

outliers <- df %>% filter(!!sym(price_col) < lower_bound | !!sym(price_col) > upper_bound)

message("\nOutlier Analysis:")
message(paste0("Interquartile Range (IQR): ", round(iqr, 2)))
message(paste0("Outlier Lower Bound: ", round(lower_bound, 2)))
message(paste0("Outlier Upper Bound: ", round(upper_bound, 2)))
message(paste0("Number of outliers: ", nrow(outliers), " (", round(nrow(outliers) / nrow(df) * 100, 2), "% of data)"))

# Step 4: Save the further cleaned data
write_csv(df, "cleaned_data.csv")
message("\nUpdated 'cleaned_data.csv' saved with prices > 0.")

```
2. Feature Engineering: Price Categorization
This section adds a new categorical column, price_class, to the dataset based on the price value. This new feature can be useful for further analysis or machine learning models.
```{r}
# Re-read the cleaned data from the previous step
df <- read_csv("cleaned_data.csv", col_types = cols(.default = "c"))

# Find the price column again
price_col <- names(df)[str_detect(tolower(names(df)), "price")][1]

# Check if the price column was found
if (is.na(price_col)) {
  stop("Error: Could not find a column representing price.")
}

message(paste0("Using '", price_col, "' as the price column."))

# Step 1: Ensure the price column is numeric before creating 'price_class'
# This is a crucial step to prevent errors
df <- df %>%
  mutate(
    # Safely convert the price column to numeric,
    # invalid parsing will result in NA
    price_numeric = as.numeric(!!sym(price_col)),
    
    # Create the new 'price_class' column based on the numeric price
    price_class = case_when(
      is.na(price_numeric) | price_numeric <= 0 ~ "Invalid Price",
      price_numeric < 150 ~ "[0,150)",
      price_numeric < 300 ~ "[150,300)",
      TRUE ~ "[300,+)"
    )
  )

# Step 2: Reorder columns to place 'price_class' at the beginning
df <- df %>%
  select(price_class, everything(), -price_numeric)

# Step 3: Save the data with the new column
write_csv(df, "cleaned_data_with_price_class.csv")
message("\nFile saved to 'cleaned_data_with_price_class.csv' with new 'price_class' column.")

```
3. Missing Value Imputation
This R code block replicates the final data cleaning step, which involves imputing missing values with specific placeholders (-1 for numeric columns and 'NA' for non-numeric columns). It also includes a function to calculate the "missing rate" based on these placeholders.
```{r}
# Load necessary libraries
# You might need to install these packages first: install.packages("tidyverse")
library(readr)
library(dplyr)
library(ggplot2)
library(stringr)

# Re-read the data
# suppressWarnings is added here as `read_csv` might generate warnings
df <- suppressWarnings(read_csv("cleaned_data_with_price_class.csv", col_types = cols(.default = "c")))

# Step 1: Identify numeric and non-numeric columns using the Python logic
numeric_cols <- character(0)
non_numeric_cols <- character(0)

for (col in names(df)) {
  sample <- df[[col]][!is.na(df[[col]]) & df[[col]] != "NA"][1:100]
  if (length(sample) > 0) {
    # suppressWarnings is used here to hide the 'NAs introduced by coercion' warnings
    numeric_count <- suppressWarnings(sum(!is.na(as.numeric(sample))))
    if (numeric_count / length(sample) > 0.8) {
      numeric_cols <- c(numeric_cols, col)
    } else {
      non_numeric_cols <- c(non_numeric_cols, col)
    }
  } else {
    non_numeric_cols <- c(non_numeric_cols, col)
  }
}

# Step 2: Impute missing values
df_imputed <- df %>%
  mutate(
    # Impute NA in numeric columns with -1
    across(all_of(numeric_cols), ~replace_na(as.numeric(.x), -1)),
    # Impute NA in non-numeric columns with 'NA'
    across(all_of(non_numeric_cols), ~replace_na(.x, 'NA'))
  )

# Step 3: Save the final cleaned data
write_csv(df_imputed, "cleaned_data_with_price_class_no_na.csv")
message("\nFinal cleaned data saved to 'cleaned_data_with_price_class_no_na.csv'.")
message(paste0("Found ", length(numeric_cols), " numeric columns."))
message(paste0("Found ", length(non_numeric_cols), " non-numeric columns."))

# Step 4: Create a function to calculate missing rates
calculate_missing_rates <- function(data) {
  missing_rates <- sapply(names(data), function(col) {
    # Check for -1 in columns that have been correctly converted to numeric
    if (is.numeric(data[[col]])) {
      sum(data[[col]] == -1) / nrow(data)
    } else {
      # Check for 'NA' or '-1' in non-numeric columns
      sum(data[[col]] %in% c('NA', '-1')) / nrow(data)
    }
  })
  sort(missing_rates * 100, decreasing = TRUE)
}

missing_rates <- calculate_missing_rates(df_imputed)
message("\nMissing rates per column (high to low):")
print(missing_rates)
```
Following this, I swapped the positions of the `id` and `price_class` columns. Then, I performed further manual data cleaning in Excel:

1.  I atomicized the `host_location` column, making the values as granular and indivisible as possible.
2.  I filtered and removed rows where column data was misaligned. I also deleted columns that were not very useful for Exploratory Data Analysis (EDA), including but not limited to:
    * `listing_url`
    * `scrape_id`
    * `description`
    * `neighborhood_overview`
    * `picture_url`
    * `host_id`
    * `host_url`
    * `host_name`
    * `host_about`
    * `host_thumbnail_url`
    * `host_picture_url`
    * `neighbourhood_group_cleansed`
    * `calendar_updated`

These features were removed either because they had little analytical value or because their missing data rate was close to 100%.

# Exploratory Data Analysis (EDA)

```{r}
library(patchwork)
library(corrplot)
library(ggplot2)
library(tidyverse)
```

```{r}
df <- read.csv("cleaned_data_with_price_class_no_dislocation.csv", encoding = "latin1")
```

## 1. Distribution of the Target Variable
The target variable price_class is divided into three ranges: low [0,150), medium [150,300), and high [300,+). As shown in the bar chart, the medium price category contains the largest proportion of listings, exceeding 4,500 entries. The low price category follows, with approximately 3,300 listings, while the high price category accounts for slightly above 3,000 listings.
```{r}
# Use a bar chart to visualize the distribution of price_class.
ggplot(df, aes(x = price_class)) +
  geom_bar(fill = "steelblue") +
  theme_minimal() +
  labs(title = "Distribution of Target Variable: price_class")
```

#### 给报告整理人员：我选择了两个分类特征，两个数值特征。如果篇幅过长，可以删除一些（如1分类，1数值）

## 2. Categorical feature

### 2.1 Room Type vs. Price Class
The distribution of room_type across price_class categories shows clear differences. Entire home/apt dominates the dataset, especially in the medium and high price ranges. Private rooms are mostly concentrated in the low-price category, while hotel rooms and shared rooms are rare and contribute minimally. This pattern highlights room type as a strong determinant of listing price, with full-property rentals generally commanding higher values.
```{r}
# Room Type vs Price Class
  ggplot(df, aes(x = room_type, fill = price_class)) +
    geom_bar(position = "dodge") +
    theme_minimal() +
    labs(title = "Room Type vs Price Class")
```


### 2.2 Neighbourhood vs. Price Class (Optional: If the length exceeds the limit, it can be deleted.)
The distribution of listings across the top 10 neighbourhoods shows notable variation in price categories. Sydney dominates the dataset, with a majority of listings in the medium and high price classes. In contrast, areas such as Auburn, Randwick, and North Sydney present a more balanced mix of low- and mid-priced properties, while suburbs like Waverley and Manly display relatively higher proportions of high-price listings. These differences highlight the strong influence of location on pricing, confirming that neighbourhood is a key determinant of property value alongside room type.

```{r}
# Step 1: Calculate the frequency and select the top ten
top_10 <- names(sort(table(df$neighbourhood_cleansed), decreasing = TRUE))[1:10]

# Step 2: Filtering data
df_subset <- df[df$neighbourhood_cleansed %in% top_10, ]

# Step 3: Visualize
ggplot(df_subset, aes(x = neighbourhood_cleansed, fill = price_class)) +
  geom_bar(position = "dodge") +
  labs(title = "Top 10 Neighbourhoods vs Price Class",
       x = "Neighbourhood",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


## 3. Numerical feature

### 给报告整理人员：对于这两个数值特征。如果篇幅过长，可以删除一个，但开头对应的“数值特征选择根据”会有所不同，请根据需要删除另外两个。

版本1（两个数值特征都保留）：

To conduct a more focused exploratory analysis, we selected two representative numerical features: accommodates and review_scores_rating. The variable accommodates directly reflects the capacity of a listing and is strongly associated with property size and pricing, making it a key determinant of price class. On the other hand, review_scores_rating captures customer satisfaction and quality perception, which are critical for understanding whether higher-priced listings also deliver better guest experiences. Together, these two features provide complementary perspectives on both the structural attributes of listings and the subjective evaluations from guests, allowing for a balanced examination of price-related patterns.

版本2（只保留 Accommodates vs. Price Class）：

The feature accommodates was selected for exploratory analysis as it directly reflects a property’s capacity and is expected to influence price. Correlation analysis further showed that accommodates, bedrooms, and beds are strongly related and positively associated with price_class. Therefore, accommodates was selected as a representative feature to examine how property’s capacity contributes to price segmentation.

版本3（只保留 Review Scores Rating vs Price Class）：

The feature review_scores_rating was selected for exploratory analysis because it directly reflects customer satisfaction and perceived quality of listings. Ratings are important indicators of trust and service standards in a market economy and are likely to influence demand and pricing strategies. By examining review ratings across different price classes, we aim to assess whether higher rated listings are associated with premium pricing, or whether lower priced listings also receive higher ratings. This analysis helps provide insight into the relationship between customer satisfaction and market positioning.


### 3.1 Accommodates vs. Price Class (Representing the size of the housing stock)
The distribution of accommodates is highly right-skewed, with the majority of listings designed to host between 1 and 4 guests, indicating that smaller properties dominate the dataset. The boxplot comparison across price_class shows a clear upward trend: higher price categories generally correspond to listings that can accommodate more guests. The median capacity for the highest price class is almost double that of the lowest class, suggesting a strong positive association between property size and price level. These findings confirm that the ability to host more guests is a key structural factor driving price segmentation.
```{r, fig.width=12, fig.height=5}
# 1. Histogram: Distribution of Accommodates
p1 <- ggplot(df, aes(x = accommodates)) +
  geom_histogram(binwidth = 1,fill = "skyblue", color = "black") +
  labs(title = "Distribution of Accommodates",
       x = "Number of Accommodates",
       y = "Count")

# 2. Box plot: Accommodates vs Price Class
p2 <- ggplot(df, aes(x = price_class, y = accommodates, fill = price_class)) +
  geom_boxplot() +
  labs(title = "Accommodates vs Price Class",
       x = "Price Class",
       y = "Accommodates") +
  theme(legend.position = "none")

p1 + p2  
```


### 3.2 Review Scores Rating vs Price Class (Representative user feedback)
The distribution of review_scores_rating is left-skewed, with most listings clustered at very high ratings, indicating that hosts generally maintain good service quality. When comparing across price_class, the boxplots show only slight differences in median ratings between low-, mid-, and high-price categories. This suggests that price is not a strong predictor of customer satisfaction, as even low-price listings achieve high ratings. The narrow interquartile ranges further confirm that review scores are consistently high regardless of price class.
```{r, fig.width=12, fig.height=5}
# 1. Histogram: Distribution of Review Scores Rating
p1 <- ggplot(df, aes(x = review_scores_rating)) +
  geom_histogram(fill = "skyblue", color = "black", bins = 30) +
  labs(title = "Distribution of Review Scores Rating",
       x = "Review Score Rating",
       y = "Count")

# 2. Box plot: Review Scores Rating vs Price Class
p2 <- ggplot(df, aes(x = price_class, y = review_scores_rating, fill = price_class)) +
  geom_boxplot() +
  labs(title = "Review Scores Rating vs Price Class",
       x = "Price Class",
       y = "Review Scores Rating") +
  theme(legend.position = "none")

p1 + p2 
```
## 4. Correlation Heatmap of Numerical Features 

To improve readability and focus on the most relevant insights, we selected the top 12 numerical features most strongly correlated with the target variable price_class. This approach highlights the variables that are most likely to influence price segmentation while avoiding excessive visual clutter from weakly related features. The resulting heatmap provides a clear view of key relationships and helps identify potential multicollinearity among the most influential predictors.
```{r}

df <- df %>% 
  mutate(price_class_numeric = case_when(
    price_class == "[0,150)" ~ 1,
    price_class == "[150,300)" ~ 2,
    price_class == "[300,+)" ~ 3,
    TRUE ~ NA_real_
  ))

# Step 1: Selection of numerical features
numeric_features <- df %>%
  select(where(is.numeric)) %>%
  select(-price_class_numeric) %>% # Excluding the numerical version of the target variable
  select(-price) 

# Step 2: Calculate the correlation of each numerical feature with the target variable
target_correlations <- numeric_features %>%
  map_dbl(~ cor(., df$price_class_numeric, use = "complete.obs")) %>%
  abs() %>%  # Take absolute values and focus on strength of correlation rather than direction
  sort(decreasing = TRUE) %>%
  head(12)   # Select the 12 features with the highest relevance


selected_features <- names(target_correlations)

# Calculate the matrix of correlation coefficients between these features
cor_matrix <- cor(numeric_features[selected_features], use = "complete.obs")

# Visualisation of heat maps
par(mar = c(0, 0, 0, 0) + 0.1) 
corrplot(cor_matrix,
         method = "square",
         type = "upper",
         tl.cex = 0.6,
         tl.col = "darkblue",
         tl.srt = 45,
         addCoef.col = "black",
         number.cex = 0.4,
         cex.main = 1.2,
         col = colorRampPalette(c("blue", "white", "red"))(100),
        )

title("Correlation Heatmap of Top 12 Numerical Features", 
      line = -2, 
      adj = 0,   
      cex.main = 1.0)

```

## 5. Class Imbalance Check
### 给报告整理人员：类别失衡检查包含price_class, room_type and neighbourhood_cleansed. 若前面分类特征EDA只选了room_type，请自行（或通知我）删除neighbourhood_cleansed的相关代码。


We examined the distribution of the target variable (price_class) and two key categorical features (room_type, neighbourhood_cleansed).

Price Class – Moderately imbalanced, with most listings in the 150–300 range. All classes remain reasonably represented.

Room Type – Strongly skewed toward entire home/apartment; private rooms are fewer, hotel/shared rooms are rare.

Neighbourhood – Highly concentrated, with Sydney dominating; other neighbourhoods have fewer listings.

Overall, class imbalance is moderate for price_class but significant for room_type and neighbourhood_cleansed, which may require weighting or stratified sampling in modeling.
```{r}
# 1. Statistical distribution tables of price_calss
desired_order <- c("[0,150)", "[150,300)", "[300,+)")

price_dist <- df %>%  
    count(price_class, name = "count") %>%  
    mutate(proportion = round(count / sum(count) * 100, 2),  
           price_class = factor(price_class, levels = desired_order)) %>%  
    arrange(price_class) 
print(price_dist)


# 2. Visualization: bar charts
p1 <- ggplot(df, aes(x = price_class)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Price Class Distribution", x = "Price Class", y = "Count") +
  theme_minimal()

p2 <- ggplot(df, aes(x = room_type)) +
  geom_bar(fill = "tomato") +
  labs(title = "Room Type Distribution", x = "Room Type", y = "Count") +
  theme_minimal()

# Only the top 10 most frequent Neighborhoods are shown.
top_neigh <- names(sort(table(df$neighbourhood_cleansed), decreasing = TRUE))[1:10]
df_top <- df[df$neighbourhood_cleansed %in% top_neigh, ]

p3 <- ggplot(df_top, aes(x = neighbourhood_cleansed)) +
  geom_bar(fill = "darkseagreen") +
  labs(title = "Top 10 Neighbourhood Distribution", x = "Neighbourhood", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

(p1 | p2) / p3

```



# Project Plan Summary
